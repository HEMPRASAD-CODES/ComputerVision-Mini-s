{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Basic transfer learning with cats and dogs data\n\n","metadata":{"id":"fYJqjq66JVQQ"}},{"cell_type":"markdown","source":"### Import tensorflow","metadata":{"id":"0oWuHhhcJVQQ"}},{"cell_type":"code","source":"try:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass","metadata":{"id":"ioLbtB3uGKPX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6eb5ebb5-31cf-4f6a-e56d-4bc7d4aa1cdc","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:24:55.435756Z","iopub.execute_input":"2025-06-11T09:24:55.435955Z","iopub.status.idle":"2025-06-11T09:24:55.442482Z","shell.execute_reply.started":"2025-06-11T09:24:55.435938Z","shell.execute_reply":"2025-06-11T09:24:55.441955Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Import modules and download the cats and dogs dataset.","metadata":{"id":"gjfMJAHPJVQR"}},{"cell_type":"code","source":"import urllib.request\nimport os\nimport zipfile\nimport random\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.optimizers import RMSprop\nfrom shutil import copyfile\n\n\ndata_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\ndata_file_name = \"catsdogs.zip\"\ndownload_dir = '/tmp/'\nurllib.request.urlretrieve(data_url, data_file_name)\nzip_ref = zipfile.ZipFile(data_file_name, 'r')\nzip_ref.extractall(download_dir)\nzip_ref.close()\n","metadata":{"id":"y23ucAFLoHop","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:24:55.444377Z","iopub.execute_input":"2025-06-11T09:24:55.444934Z","iopub.status.idle":"2025-06-11T09:25:35.453685Z","shell.execute_reply.started":"2025-06-11T09:24:55.444917Z","shell.execute_reply":"2025-06-11T09:25:35.452880Z"}},"outputs":[{"name":"stderr","text":"2025-06-11 09:24:57.476164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749633897.732201      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749633897.800139      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Check that the dataset has the expected number of examples.","metadata":{"id":"JNVXCUNUJVQR"}},{"cell_type":"code","source":"print(\"Number of cat images:\",len(os.listdir('/tmp/PetImages/Cat/')))\nprint(\"Number of dog images:\", len(os.listdir('/tmp/PetImages/Dog/')))\n\n# Expected Output:\n# Number of cat images: 12501\n# Number of dog images: 12501","metadata":{"id":"AwMoZHxWOynx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"243bd5ba-a444-4b36-ea6d-f420055de122","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:25:35.454553Z","iopub.execute_input":"2025-06-11T09:25:35.455055Z","iopub.status.idle":"2025-06-11T09:25:35.478201Z","shell.execute_reply.started":"2025-06-11T09:25:35.455022Z","shell.execute_reply":"2025-06-11T09:25:35.477480Z"}},"outputs":[{"name":"stdout","text":"Number of cat images: 12501\nNumber of dog images: 12501\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Create some folders that will store the training and test data.\n- There will be a training folder and a testing folder.\n- Each of these will have a subfolder for cats and another subfolder for dogs.","metadata":{"id":"_0riaptkJVQR"}},{"cell_type":"code","source":"try:\n    os.mkdir('/tmp/cats-v-dogs')\n    os.mkdir('/tmp/cats-v-dogs/training')\n    os.mkdir('/tmp/cats-v-dogs/testing')\n    os.mkdir('/tmp/cats-v-dogs/training/cats')\n    os.mkdir('/tmp/cats-v-dogs/training/dogs')\n    os.mkdir('/tmp/cats-v-dogs/testing/cats')\n    os.mkdir('/tmp/cats-v-dogs/testing/dogs')\nexcept OSError:\n    pass","metadata":{"id":"qygIo4W5O1hQ","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:25:35.478953Z","iopub.execute_input":"2025-06-11T09:25:35.479211Z","iopub.status.idle":"2025-06-11T09:25:36.148003Z","shell.execute_reply.started":"2025-06-11T09:25:35.479188Z","shell.execute_reply":"2025-06-11T09:25:36.147229Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Split data into training and test sets\n\n- The following code put first checks if an image file is empty (zero length)\n- Of the files that are not empty, it puts 90% of the data into the training set, and 10% into the test set.","metadata":{"id":"1ZHD_c-sJVQR"}},{"cell_type":"code","source":"import random\nfrom shutil import copyfile\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n    files = []\n    for filename in os.listdir(SOURCE):\n        file = SOURCE + filename\n        if os.path.getsize(file) > 0:\n            files.append(filename)\n        else:\n            print(filename + \" is zero length, so ignoring.\")\n\n    training_length = int(len(files) * SPLIT_SIZE)\n    testing_length = int(len(files) - training_length)\n    shuffled_set = random.sample(files, len(files))\n    training_set = shuffled_set[0:training_length]\n    testing_set = shuffled_set[training_length:]\n\n    for filename in training_set:\n        this_file = SOURCE + filename\n        destination = TRAINING + filename\n        copyfile(this_file, destination)\n\n    for filename in testing_set:\n        this_file = SOURCE + filename\n        destination = TESTING + filename\n        copyfile(this_file, destination)\n\n\nCAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\nTRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\nTESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\nDOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\nTRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\nTESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n\nsplit_size = .9\nsplit_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\nsplit_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n\n# Expected output\n# 666.jpg is zero length, so ignoring\n# 11702.jpg is zero length, so ignoring","metadata":{"id":"M90EiIu0O314","colab":{"base_uri":"https://localhost:8080/"},"outputId":"949e4212-044b-48a9-df52-249b395132d5","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:25:36.148965Z","iopub.execute_input":"2025-06-11T09:25:36.149708Z","iopub.status.idle":"2025-06-11T09:25:39.299627Z","shell.execute_reply.started":"2025-06-11T09:25:36.149682Z","shell.execute_reply":"2025-06-11T09:25:39.298515Z"}},"outputs":[{"name":"stdout","text":"666.jpg is zero length, so ignoring.\n11702.jpg is zero length, so ignoring.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Check that the training and test sets are the expected lengths.","metadata":{"id":"KMx_pePuJVQR"}},{"cell_type":"code","source":"\nprint(\"Number of training cat images\", len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\nprint(\"Number of training dog images\", len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\nprint(\"Number of testing cat images\", len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\nprint(\"Number of testing dog images\", len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n\n# expected output\n# Number of training cat images 11250\n# Number of training dog images 11250\n# Number of testing cat images 1250\n# Number of testing dog images 1250","metadata":{"id":"cl8sQpM1O9xK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4452e804-1d79-410a-db13-34d3b37bf4e6","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:25:39.300590Z","iopub.execute_input":"2025-06-11T09:25:39.300825Z","iopub.status.idle":"2025-06-11T09:25:39.330244Z","shell.execute_reply.started":"2025-06-11T09:25:39.300807Z","shell.execute_reply":"2025-06-11T09:25:39.329384Z"}},"outputs":[{"name":"stdout","text":"Number of training cat images 11250\nNumber of training dog images 11250\nNumber of testing cat images 1250\nNumber of testing dog images 1250\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Data augmentation (try adjusting the parameters)!\n\nHere, you'll use the `ImageDataGenerator` to perform data augmentation.  \n- Things like rotating and flipping the existing images allows you to generate training data that is more varied, and can help the model generalize better during training.  \n- You can also use the data generator to apply data augmentation to the validation set.\n\nYou can use the default parameter values for a first pass through this lab.\n- Later, try to experiment with the parameters of `ImageDataGenerator` to improve the model's performance.\n- Try to drive reach 99.9% validation accuracy or better.","metadata":{"id":"pNz89__rJVQR"}},{"cell_type":"code","source":"\nTRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n# Experiment with your own parameters to reach 99.9% validation accuracy or better\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=100,\n                                                    class_mode='binary',\n                                                    target_size=(150, 150))\n\nVALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                              batch_size=100,\n                                                              class_mode='binary',\n                                                              target_size=(150, 150))\n\n","metadata":{"id":"TVO1l8vAPE14","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0543c335-2616-4f8b-8234-93df903b885c","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:25:39.333287Z","iopub.execute_input":"2025-06-11T09:25:39.333607Z","iopub.status.idle":"2025-06-11T09:25:39.921731Z","shell.execute_reply.started":"2025-06-11T09:25:39.333588Z","shell.execute_reply":"2025-06-11T09:25:39.920787Z"}},"outputs":[{"name":"stdout","text":"Found 22498 images belonging to 2 classes.\nFound 2500 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Get and prepare the model\n\nYou'll be using the `InceptionV3` model.  \n- Since you're making use of transfer learning, you'll load the pre-trained weights of the model.\n- You'll also freeze the existing layers so that they aren't trained on your downstream task with the cats and dogs data.\n- You'll also get a reference to the last layer, 'mixed7' because you'll add some layers after this last layer.","metadata":{"id":"WchwDzWNJVQR"}},{"cell_type":"code","source":"weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nweights_file = \"inception_v3.h5\"\nurllib.request.urlretrieve(weights_url, weights_file)\n\n# Instantiate the model\npre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n                                include_top=False,\n                                weights=None)\n\n# load pre-trained weights\npre_trained_model.load_weights(weights_file)\n\n# freeze the layers\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n\n# pre_trained_model.summary()\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output.shape)\nlast_output = last_layer.output\n\n","metadata":{"id":"tiPK1LlMOvm7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f8059f3-8d25-4f02-eebf-553ffcc821c0","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:28:03.693515Z","iopub.execute_input":"2025-06-11T09:28:03.694054Z","iopub.status.idle":"2025-06-11T09:28:06.065501Z","shell.execute_reply.started":"2025-06-11T09:28:03.694030Z","shell.execute_reply":"2025-06-11T09:28:06.064860Z"}},"outputs":[{"name":"stdout","text":"last layer output shape:  (None, 7, 7, 768)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Add layers\nAdd some layers that you will train on the cats and dogs data.\n- `Flatten`: This will take the output of the `last_layer` and flatten it to a vector.\n- `Dense`: You'll add a dense layer with a relu activation.\n- `Dense`: After that, add a dense layer with a sigmoid activation.  The sigmoid will scale the output to range from 0 to 1, and allow you to interpret the output as a prediction between two categories (cats or dogs).\n\nThen create the model object.","metadata":{"id":"3edBz_IxJVQR"}},{"cell_type":"code","source":"# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)\n\nmodel = Model(pre_trained_model.input, x)\n","metadata":{"id":"oDidHXO1JVQR","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:28:31.115439Z","iopub.execute_input":"2025-06-11T09:28:31.115981Z","iopub.status.idle":"2025-06-11T09:28:31.159559Z","shell.execute_reply.started":"2025-06-11T09:28:31.115960Z","shell.execute_reply":"2025-06-11T09:28:31.159016Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### Train the model\nCompile the model, and then train it on the test data using `model.fit`\n- Feel free to adjust the number of epochs.  This project was originally designed with 20 epochs.\n- For the sake of time, you can use fewer epochs (2) to see how the code runs.\n- You can ignore the warnings about some of the images having corrupt EXIF data. Those will be skipped.","metadata":{"id":"asCm8okXJVQR"}},{"cell_type":"code","source":"\n# compile the model\nmodel.compile(optimizer=RMSprop(learning_rate=0.0001),\n              loss='binary_crossentropy',\n              metrics=['acc'])\n\n# train the model (adjust the number of epochs from 1 to improve performance)\nhistory = model.fit(\n            train_generator,\n            validation_data=validation_generator,\n            epochs=2,\n            verbose=1)","metadata":{"id":"3nxUncKWPRhR","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3ce58e3-16e0-4bd0-9f4a-d06a9bbcd241","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:29:26.137463Z","iopub.execute_input":"2025-06-11T09:29:26.138161Z","iopub.status.idle":"2025-06-11T09:34:12.383191Z","shell.execute_reply.started":"2025-06-11T09:29:26.138129Z","shell.execute_reply":"2025-06-11T09:34:12.382428Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1749634176.186479     112 service.cc:148] XLA service 0x7859ec0053c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1749634176.187666     112 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749634176.187690     112 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1749634177.608409     112 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/225\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - acc: 0.4850 - loss: 1.3453   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749634183.718263     112 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 76/225\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:22\u001b[0m 555ms/step - acc: 0.8148 - loss: 0.5970","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n  warnings.warn(str(msg))\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 624ms/step - acc: 0.8680 - loss: 0.3744 - val_acc: 0.9640 - val_loss: 0.0946\nEpoch 2/2\n\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 573ms/step - acc: 0.9357 - loss: 0.1537 - val_acc: 0.9512 - val_loss: 0.1247\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### Visualize the training and validation accuracy\n\nYou can see how the training and validation accuracy change with each epoch on an x-y plot.","metadata":{"id":"H6Oo6kM-JVQR"}},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.image  as mpimg\nimport matplotlib.pyplot as plt\n\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nacc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', \"Training Accuracy\")\nplt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\nplt.title('Training and validation accuracy')\nplt.figure()\n\n","metadata":{"id":"erDopoQ5eNL7","colab":{"base_uri":"https://localhost:8080/","height":487},"outputId":"fdc278e6-d19a-4d39-fca5-a53d9137a7e4","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:36:25.704818Z","iopub.execute_input":"2025-06-11T09:36:25.705411Z","iopub.status.idle":"2025-06-11T09:36:25.909933Z","shell.execute_reply.started":"2025-06-11T09:36:25.705386Z","shell.execute_reply":"2025-06-11T09:36:25.909398Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 0 Axes>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Predict on a test image\n\nYou can upload any image and have the model predict whether it's a dog or a cat.\n- Find an image of a dog or cat\n- Run the following code cell.  It will ask you to upload an image.\n- The model will print \"is a dog\" or \"is a cat\" depending on the model's prediction.","metadata":{"id":"xKc_1Qm8JVQR"}},{"cell_type":"code","source":"import numpy as np\nfrom google.colab import files\nfrom tensorflow.keras.utils import load_img, img_to_array\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n\n  # predicting images\n  path = '/content/' + fn\n  img = load_img(path, target_size=(150, 150))\n  x = img_to_array(img)\n  x /= 255\n  x = np.expand_dims(x, axis=0)\n\n  image_tensor = np.vstack([x])\n  classes = model.predict(image_tensor)\n  print(classes[0])\n  if classes[0]>0.5:\n    print(fn + \" is a dog\")\n  else:\n    print(fn + \" is a cat\")","metadata":{"id":"_0R9fsf4w29e","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"a468b303-d009-425e-869d-b816c4c41168","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:37:24.756895Z","iopub.execute_input":"2025-06-11T09:37:24.757193Z","iopub.status.idle":"2025-06-11T09:39:44.301284Z","shell.execute_reply.started":"2025-06-11T09:37:24.757172Z","shell.execute_reply":"2025-06-11T09:39:44.300310Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n     <input type=\"file\" id=\"files-c2fc0905-b44e-4daa-ace4-265c099b20e6\" name=\"files[]\" multiple disabled\n        style=\"border:none\" />\n     <output id=\"result-c2fc0905-b44e-4daa-ace4-265c099b20e6\">\n      Upload widget is only available when the cell has been executed in the\n      current browser session. Please rerun this cell to enable.\n      </output>\n      <script>// Copyright 2017 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Helpers for google.colab Python module.\n */\n(function(scope) {\nfunction span(text, styleAttributes = {}) {\n  const element = document.createElement('span');\n  element.textContent = text;\n  for (const key of Object.keys(styleAttributes)) {\n    element.style[key] = styleAttributes[key];\n  }\n  return element;\n}\n\n// Max number of bytes which will be uploaded at a time.\nconst MAX_PAYLOAD_SIZE = 100 * 1024;\n\nfunction _uploadFiles(inputId, outputId) {\n  const steps = uploadFilesStep(inputId, outputId);\n  const outputElement = document.getElementById(outputId);\n  // Cache steps on the outputElement to make it available for the next call\n  // to uploadFilesContinue from Python.\n  outputElement.steps = steps;\n\n  return _uploadFilesContinue(outputId);\n}\n\n// This is roughly an async generator (not supported in the browser yet),\n// where there are multiple asynchronous steps and the Python side is going\n// to poll for completion of each step.\n// This uses a Promise to block the python side on completion of each step,\n// then passes the result of the previous step as the input to the next step.\nfunction _uploadFilesContinue(outputId) {\n  const outputElement = document.getElementById(outputId);\n  const steps = outputElement.steps;\n\n  const next = steps.next(outputElement.lastPromiseValue);\n  return Promise.resolve(next.value.promise).then((value) => {\n    // Cache the last promise value to make it available to the next\n    // step of the generator.\n    outputElement.lastPromiseValue = value;\n    return next.value.response;\n  });\n}\n\n/**\n * Generator function which is called between each async step of the upload\n * process.\n * @param {string} inputId Element ID of the input file picker element.\n * @param {string} outputId Element ID of the output display.\n * @return {!Iterable<!Object>} Iterable of next steps.\n */\nfunction* uploadFilesStep(inputId, outputId) {\n  const inputElement = document.getElementById(inputId);\n  inputElement.disabled = false;\n\n  const outputElement = document.getElementById(outputId);\n  outputElement.innerHTML = '';\n\n  const pickedPromise = new Promise((resolve) => {\n    inputElement.addEventListener('change', (e) => {\n      resolve(e.target.files);\n    });\n  });\n\n  const cancel = document.createElement('button');\n  inputElement.parentElement.appendChild(cancel);\n  cancel.textContent = 'Cancel upload';\n  const cancelPromise = new Promise((resolve) => {\n    cancel.onclick = () => {\n      resolve(null);\n    };\n  });\n\n  // Wait for the user to pick the files.\n  const files = yield {\n    promise: Promise.race([pickedPromise, cancelPromise]),\n    response: {\n      action: 'starting',\n    }\n  };\n\n  cancel.remove();\n\n  // Disable the input element since further picks are not allowed.\n  inputElement.disabled = true;\n\n  if (!files) {\n    return {\n      response: {\n        action: 'complete',\n      }\n    };\n  }\n\n  for (const file of files) {\n    const li = document.createElement('li');\n    li.append(span(file.name, {fontWeight: 'bold'}));\n    li.append(span(\n        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n        `last modified: ${\n            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n                                    'n/a'} - `));\n    const percent = span('0% done');\n    li.appendChild(percent);\n\n    outputElement.appendChild(li);\n\n    const fileDataPromise = new Promise((resolve) => {\n      const reader = new FileReader();\n      reader.onload = (e) => {\n        resolve(e.target.result);\n      };\n      reader.readAsArrayBuffer(file);\n    });\n    // Wait for the data to be ready.\n    let fileData = yield {\n      promise: fileDataPromise,\n      response: {\n        action: 'continue',\n      }\n    };\n\n    // Use a chunked sending to avoid message size limits. See b/62115660.\n    let position = 0;\n    do {\n      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n      const chunk = new Uint8Array(fileData, position, length);\n      position += length;\n\n      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n      yield {\n        response: {\n          action: 'append',\n          file: file.name,\n          data: base64,\n        },\n      };\n\n      let percentDone = fileData.byteLength === 0 ?\n          100 :\n          Math.round((position / fileData.byteLength) * 100);\n      percent.textContent = `${percentDone}% done`;\n\n    } while (position < fileData.byteLength);\n  }\n\n  // All done.\n  yield {\n    response: {\n      action: 'complete',\n    }\n  };\n}\n\nscope.google = scope.google || {};\nscope.google.colab = scope.google.colab || {};\nscope.google.colab._files = {\n  _uploadFiles,\n  _uploadFilesContinue,\n};\n})(self);\n</script> "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2532570963.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15}]}